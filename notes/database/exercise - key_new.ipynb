{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 511: Data acquisition and pre-processing<br>Chapter 8: Establishing a Database with Documentation\n",
    "\n",
    "## Exercises\n",
    "Note: numberings refer to the main notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.2 Getting the data right, the first time\n",
    "While accessing a large dataset it might not seem convient to pre-define and execute a database structure, preprocess data, or generate metadata, but it can really save a lot of time on the back end, and should definitely be a prioroty with ongoing (streaming) data collections. Let's revisit out song lyrics exercise and do some strategic preprocessing and file management.\n",
    "\n",
    "#### 8.2.1.1 Exercise: Building a song lyrics database with metadata\n",
    "Let's work with the song lyrics scraper we created during the Harvesting Data lecture. Instead of downloading the entire dataset again and then creating our metadata files, it'd be much more efficient to rewrite our data acquisition procedure to create the metadata as it runs&mdash;upon download, we alread have each piece of data interpreted in memory, i.e.,  don't have to read from disk! The old pieces of web scraping code was just storing songs by artist in large, alphabetic data files. Here, our tasks center around making sure the songs are organized alphabeticaly by artist, and are accessible by albums and genres. We'll want to exercise care as we create data and metadata files&mdash;we need to come up with a consistent naming scheme for the different artists and songs since they don't have IDs from the website&mdash;what could go wrong if we just named files according to artist, album, song, or genre names?\n",
    "\n",
    "Pulling the pieces of scaper code together, here's a fill-in the blanks-style exercise. Complete the marked changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, re, string, json, os\n",
    "\n",
    "#######################################################################\n",
    "####### 0. Create a primary data directory. ###########################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "#######################################################################\n",
    "####### 1. Create reverse-lookup for songs by genre ###################\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "## go through all of the letters in the alphabet\n",
    "for letter in string.ascii_lowercase:\n",
    "    \n",
    "    #######################################################################\n",
    "    ####### 2. Create the letter-level directory ##########################\n",
    "    #######################################################################\n",
    "    #######################################################################\n",
    "    \n",
    "    #######################################################################\n",
    "    ####### 3. Initialize a letter-level metadata file ####################\n",
    "    ####### create a data file for the current letter\n",
    "    filename = \"songlyrics-{}.json\".format(letter)\n",
    "    fh = open(filename,  \"w\")\n",
    "    fh.close()\n",
    "    #######################################################################\n",
    "    #######################################################################\n",
    "    \n",
    "    ## open and parse the html for the current letter\n",
    "    letter_link = 'http://www.songlyrics.com/{}/'.format(letter)\n",
    "    letterhtml = requests.get(letter_link).text\n",
    "    lettersoup = BeautifulSoup(letterhtml, 'html.parser')\n",
    "\n",
    "    ## collect the pages for this letter\n",
    "    pages = [\"/{}/\".format(letter)]\n",
    "    for letterlink in lettersoup.find_all('a'):\n",
    "        ## filter links for letter pages\n",
    "        if letterlink.get(\"href\") and re.search(\"^Page \\d+$\", letterlink.get(\"title\", \"NOTITLE\")):            \n",
    "            pages.append(letterlink['href'])\n",
    "\n",
    "    ## go through the letter pages\n",
    "    for page in pages:        \n",
    "        ## open and parse the html for the current page of this letter\n",
    "        pagehtml = requests.get(\"http://www.songlyrics.com\" + page).text\n",
    "        pagesoup = BeautifulSoup(pagehtml, 'html.parser')\n",
    "\n",
    "        ## go through the artists in the page\n",
    "        for pagelink in pagesoup.find_all('a'):\n",
    "            ## filter links for artist pages\n",
    "            if re.search(\"^http://.*?-lyrics/$\", pagelink.get(\"href\", \"NOLINK\")):\n",
    "\n",
    "                #######################################################################                \n",
    "                ####### 4. remove old data structure and hold on to the artist's name \n",
    "                ####### set up data and store artist-level information\n",
    "                data = {\n",
    "                    \"Artist\": pagelink.text,\n",
    "                    \"url\": pagelink['href'],\n",
    "                    \"Songs\": {}\n",
    "                }\n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "\n",
    "                #######################################################################\n",
    "                ####### 5. Output artist info to letter-level metadata file ###########\n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "\n",
    "                #######################################################################\n",
    "                ####### 6. Create artist-level directory. #############################\n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "                \n",
    "                #######################################################################\n",
    "                ####### 7. Create an artist-level metadata file #######################\n",
    "                #######################################################################\n",
    "                #######################################################################      \n",
    "                \n",
    "                ## open and parse the html for the current artist on this page\n",
    "                artisthtml = requests.get(data[\"url\"]).text\n",
    "                artistsoup = BeautifulSoup(artisthtml, 'html.parser')                        \n",
    "\n",
    "                ## go through the songs of this artist\n",
    "                for songlink in artistsoup.find_all('a'):\n",
    "\n",
    "                    ## filter links for song pages\n",
    "                    if songlink.get(\"itemprop\", \"NOITEMPROP\") == \"url\" and songlink.get(\"title\"):\n",
    "                                                \n",
    "                        #######################################################################\n",
    "                        ############ 8. Hold song title; store info as artist-level metadata\n",
    "                        ############ store initial song-level information\n",
    "                        title = songlink.text\n",
    "                        data[\"Songs\"][title] = {\"Title\": title}\n",
    "                        data[\"Songs\"][title][\"url\"] = songlink['href']\n",
    "                        #######################################################################\n",
    "                        #######################################################################                        \n",
    "\n",
    "                        ## open and parse the html for the current song by this artist\n",
    "                        songhtml = requests.get(data[\"Songs\"][title][\"url\"]).text\n",
    "                        songsoup = BeautifulSoup(songhtml, 'html.parser')\n",
    "\n",
    "                        ## go through paragraphs to find song attributes\n",
    "                        for par in songsoup.find_all(\"p\"):\n",
    "                            if re.search(\": \", par.text):\n",
    "                                pieces = re.split(\": \", par.text)\n",
    "                                key = pieces[0]\n",
    "                                value = \": \".join(pieces[1: len(pieces)])\n",
    "\n",
    "                                #######################################################################                                \n",
    "                                ############ 9. add song attributes to artist-level metadata ##########\n",
    "                                data[\"Songs\"][title][key] = value    \n",
    "                                #######################################################################\n",
    "                                #######################################################################                        \n",
    "\n",
    "                                #######################################################################                                \n",
    "                                ############ 10. add song attributes to reverse song lookup ###########\n",
    "                                #######################################################################\n",
    "                                #######################################################################                                \n",
    "\n",
    "                        #######################################################################                                \n",
    "                        ############ 11. output song metadata to artist-level metadata file ###\n",
    "                        #######################################################################\n",
    "                        #######################################################################                                \n",
    "                                \n",
    "                        ## go through divs to find the one with the song lyrics\n",
    "                        for div in songsoup.find('body').find_all('div'):\n",
    "                            if div.get(\"id\",\"NOCLASS\") == \"songLyricsDiv-outer\":\n",
    "                                \n",
    "                                #######################################################################                                \n",
    "                                ############ 12. output song lyrics as text in artist-level directory #                                \n",
    "                                data[\"Songs\"][title][\"Lyrics\"]=div.text\n",
    "                                #######################################################################\n",
    "                                #######################################################################\n",
    "                        \n",
    "                        break\n",
    "                        \n",
    "                #######################################################################\n",
    "                #### 13. remove old data write out ####################################\n",
    "                \n",
    "                ## write out the data for this artist, appending to the end of this letter's file\n",
    "                with open(filename, \"a\") as fh:\n",
    "                    fh.writelines(json.dumps(data)+\"\\n\")\n",
    "                    \n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "                \n",
    "                break\n",
    "        break\n",
    "        \n",
    "    break\n",
    "\n",
    "#######################################################################\n",
    "####### 14. Output reverse-lookup for songs by attributes #############\n",
    "#######################################################################\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.1.2 Solution: Making the changes (Spoilers if you're doing the exercise!)\n",
    "By making a reverse lookup metadata file for artists by associated song attributes, we are denormalizing data and making it easy to perform specific transformations which are interesting for analysis. So here is the above scraper, with the additional changes we wanted to make all filled out. This is a lot, so make sure to take some time and really figure out what's going on here. If you run this code, take the time as well to review the directory structure and files it creates, and if you performed the above exercise on your own, compare your edits to those below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests, re, string, json, os\n",
    "\n",
    "#######################################################################\n",
    "####### 0. Create a primary data directory. ###########################\n",
    "os.system(\"mkdir ./data/\")\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "#######################################################################\n",
    "####### 1. Create objects for reverse-lookup of songs by genre ########\n",
    "songsByAttribute = {}\n",
    "attributeIDs = {}\n",
    "attributes = {}\n",
    "attributeNumbers = {}\n",
    "#######################################################################\n",
    "#######################################################################\n",
    "\n",
    "## go through all of the letters in the alphabet\n",
    "for letter in string.ascii_lowercase:\n",
    "\n",
    "    numartists = 0\n",
    "    \n",
    "    #######################################################################\n",
    "    ####### 2. Create the letter-level directory ##########################\n",
    "    os.system(\"mkdir ./data/{}/\".format(letter))\n",
    "    #######################################################################\n",
    "    #######################################################################    \n",
    "    \n",
    "    #######################################################################\n",
    "    ####### 3. Initialize a letter-level metadata file ####################\n",
    "    lettermetafile = \"./data/{}/lettermeta.json\".format(letter)\n",
    "    fh = open(lettermetafile,  \"w\")\n",
    "    fh.close()    \n",
    "    #######################################################################\n",
    "    #######################################################################\n",
    "    \n",
    "    ## open and parse the html for the current letter\n",
    "    letter_link = 'http://www.songlyrics.com/{}/'.format(letter)\n",
    "    letterhtml = requests.get(letter_link).text\n",
    "    lettersoup = BeautifulSoup(letterhtml, 'html.parser')\n",
    "\n",
    "    ## collect the pages for this letter\n",
    "    pages = [\"/{}/\".format(letter)]\n",
    "    for letterlink in lettersoup.find_all('a'):\n",
    "        ## filter links for letter pages\n",
    "        if letterlink.get(\"href\") and re.search(\"^Page \\d+$\", letterlink.get(\"title\", \"NOTITLE\")):            \n",
    "            pages.append(letterlink['href'])\n",
    "\n",
    "    ## go through the letter pages\n",
    "    for page in pages:        \n",
    "        ## open and parse the html for the current page of this letter\n",
    "        pagehtml = requests.get(\"http://www.songlyrics.com\" + page).text\n",
    "        pagesoup = BeautifulSoup(pagehtml, 'html.parser')\n",
    "\n",
    "        ## go through the artists in the page\n",
    "        for pagelink in pagesoup.find_all('a'):\n",
    "            ## filter links for artist pages\n",
    "            if re.search(\"^http://.*?-lyrics/$\", pagelink.get(\"href\", \"NOLINK\")):\n",
    "                \n",
    "                #######################################################################                \n",
    "                ####### 4. remove old data structure and hold on to the artist's data #\n",
    "                ####### keep track of number of artists, songs, and create an ID\n",
    "                numartists += 1\n",
    "                artistID = \"{}-{}\".format(letter, str(numartists))\n",
    "                numsongs = 0\n",
    "                \n",
    "                artist = pagelink.text\n",
    "                artisturl = pagelink['href']\n",
    "                \n",
    "                \n",
    "#                 ## set up data and store artist-level information\n",
    "#                 data = {\n",
    "#                     \"Artist\": pagelink.text,\n",
    "#                     \"url\": pagelink['href'],\n",
    "#                     \"Songs\": {}\n",
    "#                 }                \n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "\n",
    "                #######################################################################                \n",
    "                ####### 5. Output artist info to letter-level metadata file ###########\n",
    "                with open(lettermetafile,  \"a\") as f:\n",
    "                    f.writelines(artistID + \"\\t\" + artist + \"\\t\" + artisturl + \"\\n\")                    \n",
    "                #######################################################################\n",
    "                #######################################################################                    \n",
    "                    \n",
    "                #######################################################################\n",
    "                ####### 6. Create artist-level directory. #############################\n",
    "                artist_dir = './data/{}/{}/'.format(letter, artistID)\n",
    "                os.system(\"mkdir \" + artist_dir)\n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "                \n",
    "                #######################################################################\n",
    "                ####### 7. Create an artist-level metadata file #######################\n",
    "                artistmetafile = artist_dir + \"artistmeta.json\"\n",
    "                fh = open(artistmetafile,  \"w\")\n",
    "                fh.close()               \n",
    "                #######################################################################\n",
    "                #######################################################################                \n",
    "                                \n",
    "                ## open and parse the html for the current artist on this page\n",
    "                ## note we now use the artist's url!\n",
    "                artisthtml = requests.get(artisturl).text\n",
    "                artistsoup = BeautifulSoup(artisthtml, 'html.parser')                        \n",
    "\n",
    "                ## go through the songs of this artist\n",
    "                for songlink in artistsoup.find_all('a'):\n",
    "\n",
    "                    ## filter links for song pages\n",
    "                    if songlink.get(\"itemprop\", \"NOITEMPROP\") == \"url\" and songlink.get(\"title\"):                        \n",
    "\n",
    "                        #######################################################################\n",
    "                        ############ 8. Hold song title; store info as artist-level metadata ##\n",
    "                        ## keep track of number of songs and create and ID\n",
    "                        numsongs += 1\n",
    "                        titleID = \"{}-{}\".format(artistID, str(numsongs))\n",
    "                        \n",
    "                        ## hold on to the song's title\n",
    "                        title = songlink.text\n",
    "                        \n",
    "#                         data[\"Songs\"][title] = {\"Title\": title}\n",
    "#                         data[\"Songs\"][title][\"url\"] = songlink['href']\n",
    "\n",
    "                        data = {\n",
    "                            \"ID\": titleID,\n",
    "                            \"title\": title,\n",
    "                            \"url\": songlink['href']\n",
    "                        }\n",
    "                        #######################################################################\n",
    "                        #######################################################################\n",
    "\n",
    "                        ## open and parse the html for the current song by this artist\n",
    "                        ## note the data format has changed to get the song's url!\n",
    "                        songhtml = requests.get(data[\"url\"]).text\n",
    "                        songsoup = BeautifulSoup(songhtml, 'html.parser')\n",
    "\n",
    "                        ## go through paragraphs and get song attributes\n",
    "                        for par in songsoup.find_all(\"p\"):\n",
    "                            if re.search(\": \", par.text):\n",
    "                                pieces = re.split(\": \", par.text)\n",
    "                                key = pieces[0]\n",
    "                                value = \": \".join(pieces[1: len(pieces)])\n",
    "\n",
    "                                #######################################################################                                \n",
    "                                ############ 9. add song attributes to artist-level metadata ##########\n",
    "                                if key != \"Note\":\n",
    "                                    data[key] = value\n",
    "                                #######################################################################\n",
    "                                #######################################################################\n",
    "                                \n",
    "                                #######################################################################                                \n",
    "                                ############ 10. add song attributes to reverse song lookup ###########\n",
    "                                if key != \"Note\":\n",
    "                                    attributeNumbers.setdefault(key, 1)\n",
    "                                    attributeIDs.setdefault(key, {})\n",
    "                                    attributes.setdefault(key, {})\n",
    "                                    if not attributeIDs[key].get(value, False):\n",
    "                                        attributeID = \"{}-{}\".format(key, str(attributeNumbers[key]))\n",
    "                                        attributes[key][attributeID] = value\n",
    "                                        attributeIDs[key][value] = attributeID\n",
    "                                        attributeNumbers[key] += 1\n",
    "                                    else:\n",
    "                                        attributeID = attributeIDs[key][value]                                        \n",
    "                                    \n",
    "                                    songsByAttribute.setdefault(key, {})\n",
    "                                    songsByAttribute[key].setdefault(attributeID, {})\n",
    "                                    songsByAttribute[key][attributeID].setdefault(artistID, [])\n",
    "                                    songsByAttribute[key][attributeID][artistID].append(titleID)\n",
    "                                #######################################################################\n",
    "                                #######################################################################\n",
    "\n",
    "                        #######################################################################                                \n",
    "                        ############ 11. output song metadata to artist-level metadata file ###\n",
    "                        with open(artistmetafile,  \"a\") as f:\n",
    "                            f.writelines(json.dumps(data) + \"\\n\")\n",
    "                        #######################################################################\n",
    "                        #######################################################################                            \n",
    "                                \n",
    "                        ## go through divs to find the one with the song lyrics\n",
    "                        for div in songsoup.find('body').find_all('div'):\n",
    "                            if div.get(\"id\", \"NOCLASS\") == \"songLyricsDiv-outer\":\n",
    "\n",
    "                                #######################################################################                                \n",
    "                                ############ 12. output song lyrics as text in artist-level directory #\n",
    "                                title_file = \"./data/{}/{}/{}.txt\".format(letter, artistID, titleID)\n",
    "                                with open(title_file, \"w\") as f:\n",
    "                                    f.writelines(div.text + \"\\n\")\n",
    "                                \n",
    "#                                 data[\"Songs\"][title][\"Lyrics\"]=div.text\n",
    "                                #######################################################################\n",
    "                                #######################################################################\n",
    "\n",
    "                                break\n",
    "            \n",
    "                    ## now, only break after 10 songs by an artist\n",
    "                    if numsongs >= 1:\n",
    "                        break\n",
    "                        \n",
    "                #######################################################################\n",
    "                #### 13. remove old data write out ####################################\n",
    "#                 ## write out the data for this artist, appending to the end of this letter's file\n",
    "#                 with open(filename, \"a\") as fh:\n",
    "#                     fh.writelines(json.dumps(data)+\"\\n\")\n",
    "                #######################################################################\n",
    "                #######################################################################\n",
    "                \n",
    "            ## now, only break if this is the tenth artist of this letter!\n",
    "            if numartists >= 1:\n",
    "                break\n",
    "        \n",
    "        ## this stops us after one page of each letter\n",
    "        break\n",
    "        \n",
    "    ## this stops us after one letter in the alphabet\n",
    "#     break\n",
    "\n",
    "#######################################################################\n",
    "####### 14. Output reverse-lookup for songs by genre ##################\n",
    "os.system(\"mkdir ./data/Genre/\")\n",
    "fh = open(\"./data/Genre/attributeIDs.txt\", \"w\")\n",
    "for attributeID in songsByAttribute[\"Genre\"]:\n",
    "    fh.writelines(attributeID + \"\\t\" + attributes[\"Genre\"][attributeID] + \"\\n\")\n",
    "    with open(\"./data/Genre/\" + attributeID + \".json\", \"w\") as f:\n",
    "        f.writelines(json.dumps(songsByAttribute[\"Genre\"][attributeID]) + \"\\n\")\n",
    "fh.close()\n",
    "#######################################################################\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2.2.1 Exercise: accessing songs by album\n",
    "Review the `genreSongs()` function and use it as a starting point to retrieve a specific albumn's worth of song data for a specified artist. Albums and artists should be specified by string arguments. Be sure to have this functionfail gracefully/informatively if no match is found in the database! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## place code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
