{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 511: Data acquisition and pre-processing<br>Chapter 3: Acquiring Data from the Internet\n",
    "## Exercises\n",
    "Note: numberings refer to the main notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2.3 Exercise: processing a JSON response\n",
    "Make a request to the SEPTA Arrivals API to get data on the next 10 trains to arrive at Suburban Station. Store this JSON-format data into a dictionary. Inspect the dictionary structure. Then, write code to create a list containing 10 dictionaries, one for each train. These new dictionaries should look like this:\n",
    "\n",
    "#### Discussion: figuring out what we got. \n",
    "Putting together/modifying the example URL from Section 3.1.2.2 was relatively straightforward, especially since Suburban Station is exhibited with its station ID directly in the docs. The harder part is probably figuring out how to extract the information out of the json response. As it turns out, we got 20 trains: 10 each going Northbound and Southbound! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "response = requests.get(\"http://www3.septa.org/hackathon/Arrivals/Suburban Station/10\")\n",
    "\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'direction': 'S',\n",
      " 'line': 'Media/Elwyn',\n",
      " 'sched_time': '2018-08-22 17:31:01.000',\n",
      " 'status': 'On Time',\n",
      " 'track': '6'}\n"
     ]
    }
   ],
   "source": [
    "# example of train dictionary format\n",
    "train_dict = {\n",
    "    'direction': 'S',\n",
    "     'line': 'Media/Elwyn',\n",
    "     'sched_time': '2018-08-22 17:31:01.000',\n",
    "     'status': 'On Time',\n",
    "     'track': '6'\n",
    "}\n",
    "\n",
    "pprint(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'direction': 'N',\n",
      "  'line': 'Warminster',\n",
      "  'sched_time': '2018-10-16 19:04:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Paoli/Thorndale',\n",
      "  'sched_time': '2018-10-16 19:19:00.000',\n",
      "  'status': '3 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Media/Elwyn',\n",
      "  'sched_time': '2018-10-16 19:21:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '2'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Fox Chase',\n",
      "  'sched_time': '2018-10-16 19:22:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Trenton',\n",
      "  'sched_time': '2018-10-16 19:22:00.000',\n",
      "  'status': '8 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Cynwyd',\n",
      "  'sched_time': '2018-10-16 19:28:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '6'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Airport',\n",
      "  'sched_time': '2018-10-16 19:34:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '2'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Chestnut Hill West',\n",
      "  'sched_time': '2018-10-16 19:36:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Wilmington/Newark',\n",
      "  'sched_time': '2018-10-16 19:44:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Paoli/Thorndale',\n",
      "  'sched_time': '2018-10-16 19:49:00.000',\n",
      "  'status': '2 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Lansdale/Doylestown',\n",
      "  'sched_time': '2018-10-16 19:09:00.000',\n",
      "  'status': '22 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Manayunk/Norristown',\n",
      "  'sched_time': '2018-10-16 19:10:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Cynwyd',\n",
      "  'sched_time': '2018-10-16 19:11:30.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '6'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Chestnut Hill West',\n",
      "  'sched_time': '2018-10-16 19:14:00.000',\n",
      "  'status': '5 min',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Trenton',\n",
      "  'sched_time': '2018-10-16 19:18:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Warminster',\n",
      "  'sched_time': '2018-10-16 19:24:00.000',\n",
      "  'status': '9 min',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'West Trenton',\n",
      "  'sched_time': '2018-10-16 19:27:00.000',\n",
      "  'status': '4 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Warminster',\n",
      "  'sched_time': '2018-10-16 19:39:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Lansdale/Doylestown',\n",
      "  'sched_time': '2018-10-16 19:44:00.000',\n",
      "  'status': '3 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Fox Chase',\n",
      "  'sched_time': '2018-10-16 19:48:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '3'}]\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "top_keys = list(data.keys())\n",
    "# pprint(data[top_keys[0]][0][\"Northbound\"])\n",
    "\n",
    "trains = []\n",
    "for timestamp in data: ## timestamp is the sole key at the top level of response\n",
    "    for outbound_direction in data[timestamp]: ## each track direction gets its own dictionary\n",
    "        for direction in outbound_direction:\n",
    "            for train in outbound_direction[direction]:\n",
    "                trains.append({\n",
    "                    'direction': train['direction'],\n",
    "                    'line': train['line'],\n",
    "                    'sched_time': train['sched_time'],\n",
    "                    'status': train['status'],\n",
    "                    'track': train['track']\n",
    "                })\n",
    "\n",
    "pprint(trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "[{'direction': 'N',\n",
      "  'line': 'Warminster',\n",
      "  'sched_time': '2018-10-16 19:04:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Paoli/Thorndale',\n",
      "  'sched_time': '2018-10-16 19:19:00.000',\n",
      "  'status': '3 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Media/Elwyn',\n",
      "  'sched_time': '2018-10-16 19:21:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '2'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Fox Chase',\n",
      "  'sched_time': '2018-10-16 19:22:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Trenton',\n",
      "  'sched_time': '2018-10-16 19:22:00.000',\n",
      "  'status': '8 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Cynwyd',\n",
      "  'sched_time': '2018-10-16 19:28:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '6'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Airport',\n",
      "  'sched_time': '2018-10-16 19:34:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '2'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Chestnut Hill West',\n",
      "  'sched_time': '2018-10-16 19:36:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Wilmington/Newark',\n",
      "  'sched_time': '2018-10-16 19:44:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'N',\n",
      "  'line': 'Paoli/Thorndale',\n",
      "  'sched_time': '2018-10-16 19:49:00.000',\n",
      "  'status': '2 min',\n",
      "  'track': '1'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Lansdale/Doylestown',\n",
      "  'sched_time': '2018-10-16 19:09:00.000',\n",
      "  'status': '22 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Manayunk/Norristown',\n",
      "  'sched_time': '2018-10-16 19:10:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Cynwyd',\n",
      "  'sched_time': '2018-10-16 19:11:30.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '6'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Chestnut Hill West',\n",
      "  'sched_time': '2018-10-16 19:14:00.000',\n",
      "  'status': '5 min',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Trenton',\n",
      "  'sched_time': '2018-10-16 19:18:00.000',\n",
      "  'status': '1 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Warminster',\n",
      "  'sched_time': '2018-10-16 19:24:00.000',\n",
      "  'status': '9 min',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'West Trenton',\n",
      "  'sched_time': '2018-10-16 19:27:00.000',\n",
      "  'status': '4 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Warminster',\n",
      "  'sched_time': '2018-10-16 19:39:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '3'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Lansdale/Doylestown',\n",
      "  'sched_time': '2018-10-16 19:44:00.000',\n",
      "  'status': '3 min',\n",
      "  'track': '4'},\n",
      " {'direction': 'S',\n",
      "  'line': 'Fox Chase',\n",
      "  'sched_time': '2018-10-16 19:48:00.000',\n",
      "  'status': 'On Time',\n",
      "  'track': '3'}]\n"
     ]
    }
   ],
   "source": [
    "data = response.json()\n",
    "top_keys = list(data.keys())\n",
    "# pprint(data[top_keys[0]][0][\"Northbound\"])\n",
    "\n",
    "train_keys = ['direction', 'line', 'sched_time', 'status', 'track']\n",
    "\n",
    "trains = []\n",
    "for timestamp in data: ## timestamp is the sole key at the top level of response\n",
    "    for outbound_direction in data[timestamp]: ## each track direction gets its own dictionary\n",
    "        for direction in outbound_direction:\n",
    "            for train in outbound_direction[direction]:\n",
    "                trains.append({\n",
    "                    train_key: train[train_key]\n",
    "                    for train_key in train_keys\n",
    "                })\n",
    "print(len(trains))\n",
    "pprint(trains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1.1 Exercise: accessing a soccer schedule\n",
    "\n",
    "Make a request to the Sportradar Soccer schedule API to obtain the match schedule for Liverpool FC (team_id = sr:competitor:44). Then, from the obtained schedule, make a simple list of fixtures. Your output should be a list with strings as elements. The strings should be of the format \"HOME_TEAM vs AWAY_TEAM\".\n",
    "\n",
    "#### Discussion: sometimes it's easier to work with support data than logic\n",
    "This solution is a great example of when data can simplify code. If we had wanted to, we could have used `if/else` logic gates to make sure the home and away teams were always listed in the right order as we construct our fixtures. But creating the `fixture` object as a dictionary with two keys: `'home'` and `'away'` was strategic: using the _value_ of each `competitor`'s `'qualifier'` field (i.e., role as `'home'` and `'away'`) allowed us to just focus on routing each team to its appropriate position in the fixture _associatively_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Huddersfield Town vs Liverpool FC',\n",
      " 'Liverpool FC vs FK Red Star Belgrade',\n",
      " 'Liverpool FC vs Cardiff City',\n",
      " 'Arsenal FC vs Liverpool FC',\n",
      " 'FK Red Star Belgrade vs Liverpool FC',\n",
      " 'Liverpool FC vs Fulham FC',\n",
      " 'Watford FC vs Liverpool FC',\n",
      " 'Paris Saint-Germain vs Liverpool FC',\n",
      " 'Liverpool FC vs Everton FC',\n",
      " 'Burnley FC vs Liverpool FC',\n",
      " 'AFC Bournemouth vs Liverpool FC',\n",
      " 'Liverpool FC vs SSC Napoli',\n",
      " 'Liverpool FC vs Manchester United',\n",
      " 'Wolverhampton Wanderers vs Liverpool FC',\n",
      " 'Liverpool FC vs Newcastle United',\n",
      " 'Liverpool FC vs Arsenal FC',\n",
      " 'Manchester City vs Liverpool FC',\n",
      " 'Brighton & Hove Albion FC vs Liverpool FC',\n",
      " 'Liverpool FC vs Crystal Palace',\n",
      " 'Liverpool FC vs Leicester City',\n",
      " 'West Ham United vs Liverpool FC',\n",
      " 'Liverpool FC vs AFC Bournemouth',\n",
      " 'Manchester United vs Liverpool FC',\n",
      " 'Liverpool FC vs Watford FC',\n",
      " 'Everton FC vs Liverpool FC',\n",
      " 'Liverpool FC vs Burnley FC',\n",
      " 'Fulham FC vs Liverpool FC',\n",
      " 'Liverpool FC vs Tottenham Hotspur',\n",
      " 'Southampton FC vs Liverpool FC',\n",
      " 'Liverpool FC vs Chelsea FC',\n",
      " 'Cardiff City vs Liverpool FC',\n",
      " 'Liverpool FC vs Huddersfield Town',\n",
      " 'Newcastle United vs Liverpool FC',\n",
      " 'Liverpool FC vs Wolverhampton Wanderers']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# code goes here\n",
    "soccer_key = \"5a7p6zwdqwu5pkvfhhm3bd4a\"\n",
    "address = \"https://api.sportradar.us/soccer-xt3/eu/en/teams/sr:competitor:44/schedule.json?api_key=\" + soccer_key\n",
    "\n",
    "response = requests.get(address)\n",
    "\n",
    "data = response.json()\n",
    "\n",
    "fixtures = []\n",
    "for match in data['schedule']:\n",
    "    fixture = {\n",
    "        \"home\": \"\",\n",
    "        \"away\": \"\"\n",
    "    }\n",
    "    for competitor in match['competitors']:\n",
    "#         pprint(competitor)\n",
    "        fixture[competitor['qualifier']] = competitor['name']\n",
    "    \n",
    "    fixtures.append(\n",
    "        fixture['home']+\" vs \"+fixture['away']\n",
    "    )\n",
    "pprint(fixtures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.3.1 Exercise: access some accidental haikus from Twitter's REST API\n",
    "Create your Twitter API keys and download the last 15 tweets by @accidental575 (the hilarious Accidental Haiku Bot).\n",
    "\n",
    "#### Discussion: just drop your keys in, and start accessing tweets\n",
    "Working with a client is _very_ convenient, but the only reason these things exist is because the access is so valued and controled. If you haven't, sign up for a developer account and create an app today to get working with Twitter's API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "\n",
    "access_token = ''\n",
    "access_token_secret = ''\n",
    "consumer_key = ''\n",
    "consumer_secret = ''\n",
    "\n",
    "twitter = Twython(consumer_key, consumer_secret)\n",
    "\n",
    "haiku_twitter = twitter.get_user_timeline(screen_name = \"accidental575\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just writing to let /\n",
      "everyone know I have a /\n",
      "new profile picture /\n",
      "#accidentalhaiku by @BHump_12 \n",
      "https://t.co/T2usPc5C0S\n",
      "\n",
      "freelance is great cause /\n",
      "sometimes you don‚Äôt wear pants for /\n",
      "an entire day /\n",
      "#accidentalhaiku by @mattgee \n",
      "https://t.co/y48pVrBc8D\n",
      "\n",
      "Tell me you love me /\n",
      "started playing at Starbucks /\n",
      "and I gasped out loud /\n",
      "#accidentalhaiku by @ashmj21 \n",
      "https://t.co/Rfml47ypDL\n",
      "\n",
      "My dad is singing /\n",
      "Disney hits with me in the /\n",
      "car! I‚Äôm so happy ‚ù§Ô∏è /\n",
      "#accidentalhaiku by @MakaylaBickhart \n",
      "https://t.co/FmLlroSBVv\n",
      "\n",
      "Wow that‚Äôs a lot of /\n",
      "instructions on how to use /\n",
      "a public restroom! /\n",
      "#accidentalhaiku by @kbakies \n",
      "https://t.co/cE3OUt0Exh\n",
      "\n",
      "there are squirrels in /\n",
      "the Grand Canyon that carry /\n",
      "the bubonic plague /\n",
      "#accidentalhaiku by @luckyenoughlin1 \n",
      "https://t.co/bW8X9tBRDp\n",
      "\n",
      "apparently he /\n",
      "donated it to his own /\n",
      "foundation - #taxdodge /\n",
      "#accidentalhaiku by @woolkebb \n",
      "https://t.co/YNnXKnzul3\n",
      "\n",
      "Really Ain't Tryna /\n",
      "Go To Buffalo Wild Wings /\n",
      "But Imma Have To /\n",
      "#accidentalhaiku by @Im_So_Leah \n",
      "https://t.co/MJTVF79CvP\n",
      "\n",
      "I need a beach day, /\n",
      "to nap on the sand and scarf /\n",
      "down margaritas /\n",
      "#accidentalhaiku by @candicenicolexo \n",
      "https://t.co/2tQXVDmRn2\n",
      "\n",
      "If You‚Äôre Constantly /\n",
      "Overthinking Everything, /\n",
      "Try This To Chill Out /\n",
      "#accidentalhaiku by @YikesAlready \n",
      "https://t.co/0nWBUor38p\n",
      "\n",
      "I think I over /\n",
      "garlicked my chicken. Is that /\n",
      "even possible? /\n",
      "#accidentalhaiku by @lonita \n",
      "https://t.co/fi0V3QC7Bq\n",
      "\n",
      "I know. If you don‚Äôt /\n",
      "know, you gotta be in the /\n",
      "know to know, ya know? /\n",
      "#accidentalhaiku by @mylespeters42 \n",
      "https://t.co/jCri4rMbKP\n",
      "\n",
      "I'm just going to /\n",
      "go over here and rage-puke /\n",
      "for a few hours. /\n",
      "#accidentalhaiku by @HillaryWarnedUs \n",
      "https://t.co/s87jyJYGhs\n",
      "\n",
      "Trump keeps trying to /\n",
      "hide and change the facts!  Sorry /\n",
      "trumpwad, facts matter! /\n",
      "#accidentalhaiku by‚Ä¶ https://t.co/Rshu7qaRSe\n",
      "\n",
      "Ion care how good /\n",
      "life get I will forever /\n",
      "eat off paper plates üò≠ /\n",
      "#accidentalhaiku by @LoveableQua_ \n",
      "https://t.co/59DHdao7lX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in haiku_twitter[:15]:\n",
    "    print(tweet['text']+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
